# Analyse non supervis√©e de la th√©matique

```{r}
# Librairies 
library(tidytext) 
library(tidyverse)
# package de manipulation des cha√Ænes de caract√®res du tidyverse 
library(stringr)  
# package graphique devenu la r√©f√©rence sous R 
library(ggplot2)  
# package populaire d'algorithmes de text mining 
library(tm)  
library(hunspell) # contient des fonctions de parsing, tokenization, lemmatisation... 
library(janeaustenr) # 6 romans de Jane Austen 
library(wordcloud) # pour les nuages de mots 

library(forcats) # pour le graphe des tf-idf par valeur d√©croissante 

library(gutenbergr) # acc√®s √† du contenu textuel 

library(topicmodels) # mod√©lisation de th√©matiq#ues
library(caret)
library(randomForest)
```

Le mod√®le est cr√©√© par la fonction LDA() de **topicmodels**. L'argument k = 2 signifie qu'un mod√®le √† 2 th√®mes seulement est cr√©√©, mais ceci s'√©tend √† un nombre plus important en pratique. Une graine de nombres al√©atoires, via l'argument seed, est fournie pour permettre d'avoir des r√©sultats r√©p√©tables.¬†

```{r}
# Ajustement du mod√®le 
data("AssociatedPress") 
ap_lda <- LDA(AssociatedPress, k = 2, control = list(seed = 1234)) 
ap_lda 
```

La mise au format tidy du mod√®le par la fonction tidy() de **tidytext** permet d'obtenir facilement les probabilit√©s par th√®me que chacun des mots en soit issu, not√©es ùõΩ, via l'argument matrix="beta". Celles-ci sont tr√®s basses pour de nombreux mots. La fonction top_n() de dplyr permet de trouver les 10 mots les plus communs √† chaque th√®me et d'en faire le barplot via **ggplot2**.¬†

```{r}
# Obtention des probabilit√©s "par mot et par th√®me", not√©es "beta" 
ap_topics <- tidy(ap_lda, matrix = "beta") 
tibble(head(ap_topics)) 
```

Liste des 10 mots les plus communs par th√®me et barplots¬†

```{r}
ap_top_terms <- ap_topics %>% 
  filter(str_length(term)>3) %>% 
  group_by(topic) %>% 
  top_n(10, beta) %>% 
  ungroup() %>% 
  arrange(topic, -beta) 
ap_top_terms
```

```{r}
ap_top_terms %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(beta, term, fill = factor(topic))) + 
  geom_col(show.legend = FALSE) + 
  facet_wrap(~ topic, scales = "free") + 
  scale_y_reordered()
```

## Interpretation des th√®mes

Le rapide parcours de ces deux listes de mots laissent √† penser que le premier th√®me est en rapport avec le monde des affaires, le second en rapport avec la politique. Ce second th√®me doit d'ailleurs s'appuyer sur des donn√©es plut√¥t anciennes, mais probablement fortement repr√©sent√©es dans l'historique de la base, les relations USA-USSR √©tant un gros sujet politique durant des d√©cennies.¬†¬†

**Remarque**: les mots "new" et "people" sont communs aux deux th√®mes. Ils n'ont pas √©t√© plus ou moins arbitrairement affect√©s √† l'un ou l'autre th√®me, comme l'aurait fait une classification "dure" (hard clustering de la CAH ou des K-means). Ceci constitue un **important avantage** de la m√©thode : des chevauchements sont possibles, en accord avec l'usage du langage naturel.¬†

## Diff√©rences entre les th√®mes

Il est possible de rechercher les plus grandes diff√©rences en termes de ùõΩ entre les deux th√®mes. Elles sont estim√©es sur la base du rapport des log des probabilit√©s d'appartenir √† l'un ou l'autre th√®me log(ùõΩ1 / ùõΩ2), pratique car rendant les diff√©rences sym√©triques entre th√®mes.¬†

```{r}
# Tableau 
beta_spread <- ap_topics %>% 
  mutate(topic = paste0("topic", topic)) %>% 
  spread(topic, beta) %>% 
  filter(topic1 > .001 | topic2 > .001) %>% 
  mutate(log_ratio = log2(topic2 / topic1)) 
 
knitr::kable(head(beta_spread, n=10)) 
```

### Graphe des 20 plus grosses diff√©rences

```{r}
plot_log.ratio <- beta_spread %>% 
  top_n(20, abs(log_ratio)) %>% 
  arrange(desc(log_ratio))  
 
plot_log.ratio %>% 
  ggplot(aes(log_ratio, term)) + 
  geom_col(show.legend = F) + 
  ylim(plot_log.ratio$term) + 
  labs(x="Log ratio of beta in topic 2 / beta in topic 1")
```

Le th√®me 1 est plut√¥t caract√©ris√© par des noms de monnaies et des termes financiers, comme "index", "prices" ou "rates". Le second th√®me pr√©sente parmi ses termes les plus communs les noms de partis am√©ricains ou de politiciens, russes ou am√©ricains. Ceci confirme que l'algorithme a identifi√© les th√®mes financier et politique dans cette collection d'articles d'actualit√©s.¬†

## Proportion de chaque th√®me dans les documents

Le mod√®le LDA repr√©sente √©galement chaque document comme un m√©lange de th√®mes. Nous obtenons des estimations des probabilit√©s "par th√®me par document", not√©es ùõæ, via l'argument matrix="gamma".¬†

```{r}
ap_documents <- tidy(ap_lda, matrix = "gamma") %>% 
  mutate(topic = paste0("topic", topic)) %>% 
  spread(topic, gamma)
tibble(ap_documents)

# R√©cup√©ration de la th√©matique la plus probable
ap_documents_2 <- ap_documents %>% 
  mutate(max=colnames(ap_documents %>% select(-document))[apply(ap_documents %>% select(-document),1,which.max)])
tibble(ap_documents_2)
```

Chaque probabilit√© est une estimation de la proportion de mots du document issue de chacun des th√®mes. D'apr√®s le tableau ci-dessus, le document 2 aurait un peu plus d'un tiers de ses termes issus du th√®me 1 "financier".

**Remarque**: Par construction, ‚àëùõæi=1 o√π i est l'un des topic identifi√©, quelque soit le nombre k fournit √† la LDA.¬†

Le document 6 a une proportion tr√®s faible de mots issus du th√®me 1, on peut penser qu'il est essentiellement li√© au second th√®me "politique", quand le document 7 doit porter principalement sur la finance et les affaires.¬†

### Regardons quelques exemples de documents

```{r}
validation <- tidy(AssociatedPress) %>% 
  #filter(document == 6 | document==7) %>% 
  group_by(document) %>% 
  arrange(desc(count)) %>% 
  ungroup() 
 
knitr::kable(validation[validation$document == 6,][1:10,]) 
```

```{r}
knitr::kable(validation[validation$document == 7,][1:10,]) 
```

```{r}
knitr::kable(validation[validation$document == 1271,][1:10,]) 
```

```{r}
knitr::kable(validation[validation$document == 2000,][1:10,]) 
```

## Exploration de l'impact de K sur la distribution Gamma

**Exercice** : Completer le code ci dessous pour estimer le model de la LDA, r√©cup√©rer les p(t=i\|d_j) (gamma), r√©cup√©rer les p(w\|t) (betas), et lister les 15 mots les plus communs par th√®me et barplots .

```{r}
# Ajustement LDA 
ap_lda <- LDA(AssociatedPress, k = 5, control = list(seed = 1234)) 
ap_documents <- tidy(ap_lda, matrix = "gamma") 
# str(ap_lda) 
 
# Calcul des betas 
ap_topics <- tidy(ap_lda, matrix = "beta") 
 
# liste des 10 mots les plus communs par th√®me et barplots 
ap_top_terms <- ap_topics %>% 
  group_by(topic) %>% 
  top_n(15, beta) %>% 
  ungroup() %>% 
  arrange(topic, -beta) 
 
ap_top_terms %>% 
  mutate(term = reorder_within(term, beta, topic)) %>% 
  ggplot(aes(beta, term, fill = factor(topic))) + 
  geom_col(show.legend = FALSE) + 
  facet_wrap(~ topic, scales = "free") + 
  scale_y_reordered() 
```

#### Visualisation des gammas pour quelques documents¬†

```{r}
ap_documents %>% 
  dplyr::filter(document %in% c(6,7,368,31, 953, 2000, 1271)) %>% 
  ggplot(aes(x=factor(document), y=gamma, group=document, fill=factor(topic)))+ 
  geom_col(position = "fill")
```

## Repr√©sentation de donn√©es

```{r}
ap_lda_32 <- LDA(AssociatedPress, k = 8, control = list(seed = 1234, alpha=.9)) 
# alpha proche de 0 -> nb de th√©matiques par doc le plus faible possible
```

```{r}
# On r√©cup√®re uniqument le tableau des gammas sans la colonne "document"
ap_documents_32 <- tidy(ap_lda_32, matrix = "gamma") %>% 
  mutate(topic = paste0("topic", topic)) %>% 
  spread(topic, gamma) %>% 
  select(-document)
tibble(ap_documents_32)
```

```{r}
pca_res <- prcomp(ap_documents_32, scale=TRUE)
summary(pca_res)

pca_res$x %>% 
  as.data.frame %>%
  ggplot(aes(x=PC1,y=PC2)) + 
  geom_point(aes(color=ap_documents_2$max),size=4) +
  theme(legend.position="top")
```
